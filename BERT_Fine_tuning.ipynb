{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedMemon-007/AhmedMemon-007/blob/main/BERT_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQmwfIl5OsS0",
        "outputId": "f1e4a969-6bc9-47a9-a6ef-3b990cc9e533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX0HegJhPVYz"
      },
      "source": [
        "Loading the datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbEAG5U2O0X9",
        "outputId": "17bf590b-df9b-4989-db4c-12f5ac858b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   gold_label                                               text      target\n",
            "0           1  dear @Microsoft the newOoffice for Mac is grea...  @microsoft\n",
            "1           0  @Microsoft how about you make a system that do...  @microsoft\n",
            "2           1  I may be ignorant on this issue but... should ...  @microsoft\n",
            "3           1  Thanks to @user I just may be switching over t...  @microsoft\n",
            "4           2  If I make a game as a #windows10 Universal App...  @microsoft\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26632 entries, 0 to 26631\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   gold_label  26632 non-null  int64 \n",
            " 1   text        26632 non-null  object\n",
            " 2   target      26632 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 624.3+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#Lodaing the training data:\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with the actual path to your dataset in Google Drive\n",
        "file_path = '/content/drive/MyDrive/sentiment-train.csv'\n",
        "df_train = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(df_train.head())\n",
        "print(df_train.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1b3UhC6PLuf",
        "outputId": "d8ff0015-b1cc-4755-d7fd-9dd13dd8ee1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   gold_label                                               text  \\\n",
            "0           2  05 Beat it - Michael Jackson - Thriller (25th ...   \n",
            "1           3  Jay Z joins Instagram with nostalgic tribute t...   \n",
            "2           2  Michael Jackson: Bad 25th Anniversary Edition ...   \n",
            "3           3  I liked a @YouTube video {URL} One Direction s...   \n",
            "4           3  18th anniv of Princess Diana's death. I still ...   \n",
            "\n",
            "            target  \n",
            "0  michael jackson  \n",
            "1  michael jackson  \n",
            "2  michael jackson  \n",
            "3  michael jackson  \n",
            "4  michael jackson  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4000 entries, 0 to 3999\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   gold_label  4000 non-null   int64 \n",
            " 1   text        4000 non-null   object\n",
            " 2   target      4000 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 93.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Validation data\n",
        "# Replace with the actual path to your dataset in Google Drive\n",
        "file_path = '/content/drive/MyDrive/sentiment-validation.csv'\n",
        "df_val = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(df_val.head())\n",
        "print(df_val.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J5TQSvUPQS-",
        "outputId": "9e507eac-608a-40de-f64e-7fb42163dd68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   gold_label                                               text  \\\n",
            "0           2  #ArianaGrande Ari By Ariana Grande 80% Full {U...   \n",
            "1           3  Ariana Grande KIIS FM Yours Truly CD listening...   \n",
            "2           3  Ariana Grande White House Easter Egg Roll in W...   \n",
            "3           3  #CD #Musics Ariana Grande Sweet Like Candy 3.4...   \n",
            "4           3  SIDE TO SIDE 😘 @user #sidetoside #arianagrande...   \n",
            "\n",
            "          target  \n",
            "0  #ArianaGrande  \n",
            "1  #ArianaGrande  \n",
            "2  #ArianaGrande  \n",
            "3  #ArianaGrande  \n",
            "4  #ArianaGrande  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12379 entries, 0 to 12378\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   gold_label  12379 non-null  int64 \n",
            " 1   text        12379 non-null  object\n",
            " 2   target      12379 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 290.3+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#Test data\n",
        "\n",
        "# Replace with the actual path to your dataset in Google Drive\n",
        "file_path = '/content/drive/MyDrive/sentiment-test.csv'\n",
        "df_test = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(df_test.head())\n",
        "print(df_test.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90zhxCckPX-Y"
      },
      "source": [
        "### Preprocessing the text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P064OyGoPSYd",
        "outputId": "7f63b7c3-afa0-4d3d-c5bb-eda49791e526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gold_label\n",
            "2    11735\n",
            "3    10984\n",
            "1     2869\n",
            "4      819\n",
            "0      225\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Verify the label distribution\n",
        "print(df_train['gold_label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYIGzAbLPgoQ",
        "outputId": "6b3c0e37-63ca-4c67-d65a-0e801e47cba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gold_label    0\n",
            "text          0\n",
            "target        0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df_train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aJOPZbTgPl2N",
        "outputId": "0972da0f-159a-4479-97c8-1524a40d3414"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train[['text', 'cleaned_text']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"@Microsoft how about you make a system that doesn't eat my friggin discs. This is the 2nd time this has happened and I am so sick of it!\",\n          \"If I make a game as a #windows10 Universal App. Will #xboxone owners be able to download and play it in November? @majornelson @Microsoft\",\n          \"I may be ignorant on this issue but... should we celebrate @user parental leave changes? Doesn't the gender divide suggest... (1/2)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[USER] how about you make a system that doesn't eat my friggin discs. This is the 2nd time this has happened and I am so sick of it!\",\n          \"If I make a game as a #windows10 Universal App. Will #xboxone owners be able to download and play it in November? [USER] [USER]\",\n          \"I may be ignorant on this issue but... should we celebrate [USER] parental leave changes? Doesn't the gender divide suggest... (1/2)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7fd7f0af-82b2-4c84-86fb-2057cfa1cf32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
              "      <td>dear [USER] the newOoffice for Mac is great an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Microsoft how about you make a system that do...</td>\n",
              "      <td>[USER] how about you make a system that doesn'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I may be ignorant on this issue but... should ...</td>\n",
              "      <td>I may be ignorant on this issue but... should ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thanks to @user I just may be switching over t...</td>\n",
              "      <td>Thanks to [USER] I just may be switching over ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If I make a game as a #windows10 Universal App...</td>\n",
              "      <td>If I make a game as a #windows10 Universal App...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fd7f0af-82b2-4c84-86fb-2057cfa1cf32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fd7f0af-82b2-4c84-86fb-2057cfa1cf32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fd7f0af-82b2-4c84-86fb-2057cfa1cf32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2b5b1eb9-a5c3-4743-a505-066167dd18b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b5b1eb9-a5c3-4743-a505-066167dd18b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2b5b1eb9-a5c3-4743-a505-066167dd18b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  dear @Microsoft the newOoffice for Mac is grea...   \n",
              "1  @Microsoft how about you make a system that do...   \n",
              "2  I may be ignorant on this issue but... should ...   \n",
              "3  Thanks to @user I just may be switching over t...   \n",
              "4  If I make a game as a #windows10 Universal App...   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  dear [USER] the newOoffice for Mac is great an...  \n",
              "1  [USER] how about you make a system that doesn'...  \n",
              "2  I may be ignorant on this issue but... should ...  \n",
              "3  Thanks to [USER] I just may be switching over ...  \n",
              "4  If I make a game as a #windows10 Universal App...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Function to preprocess text for BERT\n",
        "def preprocess_text_for_bert(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Replace mentions with placeholder [USER]\n",
        "    text = re.sub(r\"@\\w+\", '[USER]', text)\n",
        "\n",
        "    # Preserve hashtags, casing, and punctuation\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to the text column\n",
        "df_train['cleaned_text'] = df_train['text'].apply(preprocess_text_for_bert)\n",
        "df_val['cleaned_text'] = df_val['text'].apply(preprocess_text_for_bert)\n",
        "df_test['cleaned_text'] = df_test['text'].apply(preprocess_text_for_bert)\n",
        "\n",
        "\n",
        "# Display a few rows\n",
        "df_train[['text', 'cleaned_text']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2H2k9F1RCo_",
        "outputId": "84d45587-0b85-402a-a801-5290f504e65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   gold_label                                       cleaned_text\n",
            "0           1  dear [USER] the newOoffice for Mac is great an...\n",
            "1           0  [USER] how about you make a system that doesn'...\n",
            "2           1  I may be ignorant on this issue but... should ...\n",
            "3           1  Thanks to [USER] I just may be switching over ...\n",
            "4           2  If I make a game as a #windows10 Universal App...\n"
          ]
        }
      ],
      "source": [
        "# Drop unnecessary columns from all datasets\n",
        "df_train = df_train.drop(columns=['text', 'target'])\n",
        "df_val = df_val.drop(columns=['text', 'target'])\n",
        "df_test = df_test.drop(columns=['text', 'target'])\n",
        "\n",
        "# Verify the preprocessed datasets\n",
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS9bY_20RIxp",
        "outputId": "8f4f8a33-8dd6-49e3-f4c7-e96be7f6bffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['gold_label', 'cleaned_text'], dtype='object')\n",
            "Index(['gold_label', 'cleaned_text'], dtype='object')\n",
            "Index(['gold_label', 'cleaned_text'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_train.columns)\n",
        "print(df_val.columns)\n",
        "print(df_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p62FtAunbaq7"
      },
      "source": [
        "### Tokenization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "58e150e3b72b45838594b92c311ea520",
            "0f2e8d7336084dd8b9cb31412aec2739",
            "e75304a637414ab98e3655b553671238",
            "ea6c0291e12c4db98df9858f8f465c51",
            "4a6189fa15d24978be46633859590589",
            "729563145f3149f897a61367e99eea25",
            "a8ddfebc91cb47998e661b5e2aafc665",
            "0f9d5813518c47748c781d19338af8cc",
            "d7acf1b50d4149458b9a0f416a55963a",
            "1d652cdc095d44baa734e945fda09752",
            "ba4acd6903134b2cb22a88520e6129ec",
            "99659112c6fa481c811b0f711feea337",
            "da2e8d08194842b6a330e5a84a4cc4a7",
            "56c7dccc48234317baa9cde7f315a92b",
            "f8c32e8a122c4ccf8a1502227e9ce86f",
            "e4a4e6e900d241a0b7c0140d027464a1",
            "0f574571c659409cae0485b8ddb07fbc",
            "ff96ab672b1249bb90d51a444cbbaf80",
            "891367c60616469597db9a11863a329f",
            "a24d9931cac443dc88ace6038755d1b2",
            "506e195986684952aaf2be851fbb9780",
            "d83b81b2f2fe45e1bb557dd093dcb72d",
            "3dc3a072dc80495c862fd8af821482de",
            "f98f797972f947efaf83c819bfc8c09f",
            "05eadc8f1c9645ca8d56011cb9e38865",
            "e328107d62cd433681351a977d073204",
            "b68c1d56208e448a98fb12f6dc53391d",
            "e2983b57004349d9b5d6e2fcadad39c4",
            "c99fdba628c1445da3ded5b7c9070ff8",
            "2206a032c04b42b9bc791eb2267d41ec",
            "6d501b79e0304577bbc37a05c7c1b7de",
            "2c484fc186eb470e84f8acf6995c099b",
            "6f8a062682744029aa3e3dd6416a0ff7",
            "96d044365e7c4885a676abb15cf8c9ed",
            "15bb3ad639274b3e956b043a1719593e",
            "cafb671183da42a1825acefc888759d7",
            "046099be676441888bb534b356809115",
            "53fbc1c33ecd4ec38e19f4ce7d3f9a66",
            "3eaa6a54321e4d9e8f23097a6d4e2326",
            "913eddb08f814ba299c0a564afd14c3f",
            "3ff868442b5446c6ac000320f6e0c93e",
            "3ac361790a2b47d98fb75ce8507201bc",
            "835e3fb3c1ae42a589fe3cfa9f4c4e82",
            "bdf3e7e3e67f4038bceec0f0ad0a7b24"
          ]
        },
        "id": "nFJns-MqRV76",
        "outputId": "0dd74132-1d1a-4608-ba74-5be48c3fb673"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58e150e3b72b45838594b92c311ea520",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99659112c6fa481c811b0f711feea337",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dc3a072dc80495c862fd8af821482de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96d044365e7c4885a676abb15cf8c9ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 6203, 1031, 5310, 1033, 1996, 2047, 21511, 8873, 3401, 2005, 6097, 2003, 2307, 1998, 2035, 1010, 2021, 2053, 1048, 6038, 2278, 10651, 1029, 1039, 1005, 12256, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DataCollatorWithPadding\n",
        "\n",
        "# Load the DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenization function (without padding)\n",
        "def tokenize_function(text):\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        truncation=True,       # Truncate sequences longer than max_length\n",
        "        max_length=128,        # Optional max_length cap\n",
        "    )\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_data = df_train['cleaned_text'].apply(tokenize_function)\n",
        "tokenized_val = df_val['cleaned_text'].apply(tokenize_function)\n",
        "tokenized_test = df_test['cleaned_text'].apply(tokenize_function)\n",
        "\n",
        "# View the first tokenized result (no padding applied yet)\n",
        "print(tokenized_data.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPES0l0kjPd-"
      },
      "source": [
        "### Initialising the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673,
          "referenced_widgets": [
            "a44b2380e4b246b296e6e64d976d3c3d",
            "e2fa77dc088a422bb0df82775613662f",
            "a8d916881aee4a0482febf85b366a1a8",
            "1c41c028587e440e8fdedaba06833248",
            "c67c1a659b6d45358602495ca860b60c",
            "5b6cd55f0c244b08aa1bae456ff4420c",
            "e3af8938fbef476eaff749ce000d44ab",
            "805295a411f94f429ade7928f7abab27",
            "f570dba8e8584855b14af68e20105b58",
            "824db517d54842d18362bc018d782a22",
            "9f1979950be94e409ac2813b7e203074"
          ]
        },
        "id": "L6OvDrCgf673",
        "outputId": "6bc03bd3-9ca3-4835-b22f-645ec5724799"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a44b2380e4b246b296e6e64d976d3c3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): DistilBertSdpaAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForSequenceClassification  #Using DistilBERT as it is lighter and faster for fine-tuning while maintaining strong performance.\n",
        "\n",
        "# Load the DistilBERT model with a classification head\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",  # Pre-trained DistilBERT\n",
        "    num_labels=5               # Number of sentiment labels (0-4)\n",
        ")\n",
        "\n",
        "# Check model architecture\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NARXy7TC25Qe"
      },
      "source": [
        "Weighted loss function and optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxITgzVmj8Iz",
        "outputId": "2aeb4422-1e27-438e-afcc-eb4bedf3eedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: tensor([23.6729,  1.8565,  0.4539,  0.4849,  6.5035])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.optim import AdamW  # Import AdamW from PyTorch\n",
        "\n",
        "\n",
        "# Calculate class weights based on the training data\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",  # Balances based on class frequency\n",
        "    classes=np.array([0, 1, 2, 3, 4]),  # Sentiment classes\n",
        "    y= df_train['gold_label']  # Replace with your training labels (actual numbers)\n",
        ")\n",
        "\n",
        "# Convert weights to PyTorch tensor\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Define weighted loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Example: Print class weights to confirm\n",
        "print(f\"Class Weights: {class_weights}\")\n",
        "\n",
        "\n",
        "# Replace Hugging Face's AdamW with PyTorch's AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArsI1Tv-7AEt"
      },
      "source": [
        "Specifying the settings of the model : (Define training arguements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu1FAF366akt",
        "outputId": "ac76ed8d-d238-4f53-b6e3-28aaf93a6c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.EPOCH,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./logs,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=accuracy,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./results,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=./results,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.EPOCH,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # Directory to save model checkpoints\n",
        "    evaluation_strategy=\"epoch\",    # Evaluate after each epoch\n",
        "    save_strategy=\"epoch\",          # Save model after each epoch\n",
        "    logging_dir=\"./logs\",           # Directory for training logs\n",
        "    learning_rate=5e-5,             # Learning rate\n",
        "    per_device_train_batch_size=16, # Batch size per device\n",
        "    per_device_eval_batch_size=16,  # Batch size for evaluation\n",
        "    num_train_epochs=3,             # Number of training epochs\n",
        "    weight_decay=0.01,              # Weight decay for regularization\n",
        "    logging_steps=10,               # Log training metrics every 10 steps\n",
        "    save_total_limit=2,             # Keep only 2 latest checkpoints\n",
        "    load_best_model_at_end=True,    # Automatically load the best model\n",
        "    metric_for_best_model=\"accuracy\", # Metric to determine the best model\n",
        "    report_to=\"none\"                # Avoid reporting to any third-party service\n",
        ")\n",
        "\n",
        "# Print the configuration to confirm\n",
        "print(training_args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjyXGWf8Z2GB"
      },
      "source": [
        "### Preparing the training dataset to train using the trainer function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdzjSPHRU1Zq",
        "outputId": "920275c6-fdfb-496e-a8ea-397b1faf7f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gch1etV3FPLb"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def create_dataset(tokenized_data, labels):\n",
        "  input_ids = [x['input_ids'] for x in tokenized_data]\n",
        "  attention_mask = [x['attention_mask'] for x in tokenized_data]\n",
        "  return Dataset.from_dict({\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels\n",
        "    })\n",
        "\n",
        "# Use this function for all datasets\n",
        "train_data = create_dataset(tokenized_data, df_train['gold_label'].tolist())\n",
        "val_data = create_dataset(tokenized_val, df_val['gold_label'].tolist())\n",
        "test_data = create_dataset(tokenized_test, df_test['gold_label'].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yXzMe6Od_JK"
      },
      "source": [
        "## Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "i6wrYtO_XFDr",
        "outputId": "190f14ef-e943-424b-89f3-15053c549536"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4995' max='4995' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4995/4995 07:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.680100</td>\n",
              "      <td>1.035549</td>\n",
              "      <td>0.557000</td>\n",
              "      <td>0.539365</td>\n",
              "      <td>0.557000</td>\n",
              "      <td>0.534405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.627700</td>\n",
              "      <td>1.190973</td>\n",
              "      <td>0.546000</td>\n",
              "      <td>0.550783</td>\n",
              "      <td>0.546000</td>\n",
              "      <td>0.534998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.345700</td>\n",
              "      <td>1.521673</td>\n",
              "      <td>0.536250</td>\n",
              "      <td>0.541935</td>\n",
              "      <td>0.536250</td>\n",
              "      <td>0.526922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4995, training_loss=0.6012527651018328, metrics={'train_runtime': 430.8347, 'train_samples_per_second': 185.445, 'train_steps_per_second': 11.594, 'total_flos': 880727639781600.0, 'train_loss': 0.6012527651018328, 'epoch': 3.0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "# Create a data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Define compute_metrics function\n",
        "def compute_metrics(pred):\n",
        "    predictions, labels = pred\n",
        "    predictions = predictions.argmax(axis=1)  # Get the class with highest probability\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "# Update the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    #tokenizer=tokenizer,\n",
        "    data_collator=data_collator,  # Enables dynamic padding\n",
        "    compute_metrics=compute_metrics  # Add the metrics function here\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "rzQfy66PcXhj",
        "outputId": "f75f1835-9bbe-42c4-d562-89a56d530eb5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Set Results:\n",
            "eval_loss: 1.0355490446090698\n",
            "eval_accuracy: 0.557\n",
            "eval_precision: 0.5393649223948135\n",
            "eval_recall: 0.557\n",
            "eval_f1: 0.5344050808322578\n",
            "eval_runtime: 5.0265\n",
            "eval_samples_per_second: 795.782\n",
            "eval_steps_per_second: 49.736\n",
            "epoch: 3.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "  # Evaluate the model on the test dataset\n",
        "val_results = trainer.evaluate(val_data)\n",
        "\n",
        "# Print the Vailidation results\n",
        "print(\"Validation Set Results:\")\n",
        "for key, value in val_results.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Tb3ZrGnhlBpU",
        "outputId": "d1694b83-21d1-4471-bf94-549b5b3ce2a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1024' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:34]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Results:\n",
            "eval_loss: 0.8832032084465027\n",
            "eval_accuracy: 0.5931012198077389\n",
            "eval_precision: 0.5916389531740106\n",
            "eval_recall: 0.5931012198077389\n",
            "eval_f1: 0.5867535011946092\n",
            "eval_runtime: 15.8597\n",
            "eval_samples_per_second: 780.531\n",
            "eval_steps_per_second: 48.803\n",
            "epoch: 3.0\n"
          ]
        }
      ],
      "source": [
        "  # Evaluate the model on the test dataset\n",
        "test_results = trainer.evaluate(test_data)\n",
        "\n",
        "# Print the test results\n",
        "print(\"Test Set Results:\")\n",
        "for key, value in test_results.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs9WljNza8N9"
      },
      "source": [
        "Saving the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "0-3KR4rBcXkj",
        "outputId": "5840b510-6611-44f1-87ca-a9bcb257ff63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer saved successfully!\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# Load the model and tokenizer\\nmodel = DistilBertForSequenceClassification.from_pretrained(\"./fine_tuned_distilbert\")\\ntokenizer = DistilBertTokenizer.from_pretrained(\"./fine_tuned_distilbert\")\\n\\nprint(\"Model and tokenizer loaded successfully!\") '"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model and tokenizer\n",
        "model.save_pretrained(\"./fine_tuned_distilbert\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_distilbert\")\n",
        "\n",
        "print(\"Model and tokenizer saved successfully!\")\n",
        "\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
        "\n",
        "'''# Load the model and tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"./fine_tuned_distilbert\")\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"./fine_tuned_distilbert\")\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully!\") '''\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}